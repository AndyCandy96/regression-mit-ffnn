<!DOCTYPE html>
<html lang="de">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Regression mit FFNN</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
  <link rel="stylesheet" href="style.css">
</head>
<body>
    <main>
    <h1>Deep Learning Einsendeaufgabe 2 - Regression mit FFNN
        <p id="status"></p>
    </h1> <h3>Name: Andre Zahn <br/> Hochschule: Ostfalia <br/> Matrikelnummer: 70487656 </h3>

    <script src="data.js"></script>
    <script src="model_training.js"></script>
      

    <h2>R1: Datensätze</h2>
        <div style="display: flex; gap: 20px;">
        <div>
        <h3>Ohne Rauschen</h3>
        <canvas id="dataPlotClean" width="400" height="300"></canvas>
        </div>
        <div>
        <h3>Mit Rauschen</h3>
        <canvas id="dataPlotNoisy" width="400" height="300"></canvas>
        </div>
    </div>

    <h2>R2: Vorhersage des "Clean Model" - Trainiert mit 500 Epochen</h2>
        <div style="display: flex; gap: 20px;">
        <div>
        <h3>Vergleich mit unverrauschten Trainingsdaten</h3>
        <canvas id="canvasCleanTrain" width="400" height="300"></canvas>
        </div>
        <div>
        <h3>Vergleich mit unverrauschten Testdaten</h3>
        <canvas id="canvasCleanTest" width="400" height="300"></canvas>
        </div>
    </div>

    <h2>R3: Vorhersage des "Best-Fit Model" - Trainiert mit 385 Epochen</h2>
        <div style="display: flex; gap: 20px;">
        <div>
        <h3>Vergleich mit verrauschten Trainingsdaten</h3>
        <canvas id="canvasBestFitTrain" width="400" height="300"></canvas>
        </div>
        <div>
        <h3>Vergleich mit verrauschten Testdaten</h3>
        <canvas id="canvasBestFitTest" width="400" height="300"></canvas>
        </div>
    </div>

    <h2>R4: Vorhersage des "Overfit Model" - Trainiert mit 2500 Epochen</h2>
        <div style="display: flex; gap: 20px;">
        <div>
        <h3>Vergleich mit verrauschten Trainingsdaten</h3>
        <canvas id="canvasOverfitTrain" width="400" height="300"></canvas>
        </div>
        <div>
        <h3>Vergleich mit verrauschten Testdaten</h3>
        <canvas id="canvasOverfitTest" width="400" height="300"></canvas>
        </div>
    </div>
      
        
    </div>

    <section id="discussion">
        <h2>Diskussion:</h2>
        <p class="blocksatz">
            Die Datenpunkte liegen wie erwartet, unverrauscht exakt der Ground-Truth-Funktion folgend und verrauscht zufällig drumherum verteilt.
            Aufgrund von Lücken im Verlauf der Daten kann selbst das Clean Model am Anfang des Ausschnitts bei x = -2 den richtigen Wert nicht exakt approximieren.
            Mit jeder Epoche verbessert sich das Clean Model, ohne overzufitten, da es unverrauscht die Ground Truth erkennen kann, welche als Polynom eine glatte, stetig differenzierbare Funktion ist, die neuronale Netze mit mindestens einem hidden Layer und genügend Neuronen besonders gut lernen können.  
            Ich visualisierte den Verlauf von Trainings- und Test-Loss in einer Hilfsklasse, um den Best-Fit-Punkt nach einer bestimmten Epochenanzahl und das darauf folgende Overfitting zu erkennen.
            Ich hätte gedacht, dass das Overfitting deutlicher sichtbar wird, doch immerhin stieg wie erwartet der Test-Loss wieder an (auch wenn nur leicht) während der Trainings-Loss weiter sank, was sich kontinuierlich fortsetzte. 
            Zwischen 380 und 390 Epochen zeigte der Test-Loss die häufigsten Tiefpunkte, daher wählte ich 385 Epochen für das Best-Fit Model.
            Den Unterschied zwischen dem Best-Fit Model und dem Overfit Model erkennt man besonders daran, dass das Overfit Model in seiner Prediction die Testdaten für die Trainingsdaten total vernachlässigt, während das Best Fit Model beide gleich berücksichtigt.
            Die Kurve des Best-Fit Models ist wesentlich runder und flüssiger als die Kurve, des Overfit Models, welche versucht Trainingsdaten zu erreichen und sich dabei in den Lücken dazwischen immer wieder stärker von der Ground Truth entfernt.
           

        </p>
    </section>

    <section id="documentation">
        <h2>Dokumentation:</h2>
        <h3>Technisch:</h3>
        <p>Die wichtigsten Dateien bzw. Klassen in diesem TensorFlow-JavaScript-Projekt sind:
        <ul>
            <li><p class="blocksatz"><b>data.js :</b> Hier werden in JavaScript die generierten Datenpunkte, aufgelistet und für das Modelltraining vorbereitet.</p></li>
            <li><p class="blocksatz"><b>model_training.js :</b> Hier werden in JavaScript die Modelle trainiert oder geladen, falls es das entsprechende Modell bereits gibt. Sie können auch gelöscht und neu trainiert werden. Außerdem werden hier von den Modellen die Predictions berechnet und gemeinsam mit entsprechenden unverrauschten bzw. verrauschten Trainings- bzw. Testdaten visualisiert.</p></li>
            <li><b>style.css :</b> - für das Styling in CSS</li><br>
            <li><b>index.html :</b> - für die Struktur der Weboberfläche</li> 
        </ul>
        <p>Dateien, die für das Training und Testen benutzt wurden:
            <ul>
                <li><p class="blocksatz"><b>data_original.js :</b> Hier wurden in JavaScript die Datenpunkte auf der Ground Truth Funktion generiert und im Local-Storage gespeichert.</p></li>
                <li><p class="blocksatz"><b>model_training_original.js :</b> Hier wurden in JavaScript die Modelle definiert und trainiert.</p></li>
                <li><p class="blocksatz"><b>model_loss_evaluator.js :</b> Hier habe ich mir die Trainings- und Test-Loss Verläufe entlang der Epochen anzeigen lassen, um die Epochen Anzahl für das Best Fit Model zu ermintteln. </p></li>
            </ul>
        Folgende externe Frameworks wurden eingebunden:
        <ul>
            <li><b>TensorFlow</b> wird verwendet, um neuronale Netze direkt im Browser zu definieren, zu trainieren und für Vorhersagen zu nutzen bzw. diese zu berechnen.</li><br>
            <li><b>Chart.js</b> Visualisierung der Klassifikationsergebnisse: Es erzeugt anschauliche Diagramme wie Scatterplots, um Trainingsdaten, Testdaten und Modellvorhersagen visuell darzustellen.</li>
        </ul>
        </p>

        <h3>Fachlich:</h3>
        <p>Entwicklungsschritte:
            <ul>
            <li>Entwicklung der Projekt-Grundstruktur (Ordner und Dateien)</li>
            <li>Hosting auf GitHub-Pages</li> 
            <li>Generierung der Datenpunkte</li>
            <li>Training der Modelle und Ausprobieren verschiedener Parameter: Anzahl der Epochen, Anzahl der Layer, Anzahl der Units, Verschiedene Datenpunkte</li>
            <li>Kompletter Umbau des Projekts, da ich mit dem Speichern im Local-Storage besonders Schwierigkeiten hatte</li>
            <li>Zusammenbau und Fertigstellung des Projekts</li>
            <li>Diskussion und Dokumentation</li>
            <li>Viele Versuche die Modelle zu speichern, welche alle an kleinen Details scheiterten</li>
            </ul>

            Hilfsmittel und Quellen:
            <ul>
            <li>https://codelabs.developers.google.com/codelabs/tfjs-training-regression</li>
            <li>https://stackoverflow.com</li>
            <li>https://chatgpt.com</li>
            <li>https://www.tensorflow.org/js/</li>
            <li>https://fmennen.de/post/java-script-schreiben-von-daten-in-eine-datei</li>
            <li>https://www.w3schools.com/Js/js_async.asp</li>
            <li>https://medium.com/@chhavikhandelwal/ensuring-smooth-execution-how-to-wait-for-objects-on-window-load-in-javascript-a39fbd1d2e73</li>
            </ul>
        </p>
        </section>
  
    </main>
</body>
</html>

